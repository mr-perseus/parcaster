{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Bp7xn6t5qL_"
   },
   "source": [
    "\n",
    "# Hyperparameter Sweeps\n",
    "\n",
    "In this project, we use Hyperparemter sweeps with Pytorch on \"Weights & Biases\". For further details, check out this [Colab](http://wandb.me/sweeps-colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjckmLcx5qL_"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Start out by installing the experiment tracking library and setting up your free W&B account:\n",
    "\n",
    "1. Install with `!pip install`\n",
    "2. `import` the library into Python\n",
    "3. `.login()` so you can log metrics to your projects\n",
    "\n",
    "If you've never used Weights & Biases before,\n",
    "the call to `login` will give you a link to sign up for an account.\n",
    "W&B is free to use for personal and academic projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb -Uq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T12:38:11.955714800Z",
     "start_time": "2023-11-24T12:38:11.743513300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import wandb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T12:38:12.408532500Z",
     "start_time": "2023-11-24T12:38:11.959710400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmr-perseus\u001B[0m (\u001B[33mparcaster\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T12:38:13.709369200Z",
     "start_time": "2023-11-24T12:38:12.437691700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiEyBrQm5qMB"
   },
   "source": [
    "## Defining the sweep config\n",
    "\n",
    "We define the sweep config via dict in our Jupyter notebook. You can find more information on sweeps in the [documentation](https://docs.wandb.com/sweeps/configuration).\n",
    "\n",
    "You can find a list of all configuration options [here](https://docs.wandb.com/library/sweeps/configuration) and a big collection of examples in YAML format [here](https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ilZtMXIA5qMC",
    "ExecuteTime": {
     "end_time": "2023-11-24T15:15:40.506305200Z",
     "start_time": "2023-11-24T15:15:40.466167500Z"
    }
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  'method': 'random',\n",
    "  'metric': {\n",
    "    'goal': 'minimize',\n",
    "    'name': 'loss'\n",
    "  },\n",
    "  'parameters': {\n",
    "    'batch_size': {\n",
    "      'distribution': 'q_log_uniform_values',\n",
    "      'max': 256,\n",
    "      'min': 32,\n",
    "      'q': 8\n",
    "    },\n",
    "    'dropout': {\n",
    "      'values': [0.3, 0.4, 0.5]\n",
    "    },\n",
    "    'num_layers': {\n",
    "      'values': [1, 2, 3]  \n",
    "    },\n",
    "    'epochs': {\n",
    "      'values': [1, 2, 3]\n",
    "    },\n",
    "    'fc_layer_size': {\n",
    "      'values': [50, 100, 200]\n",
    "    },\n",
    "    'learning_rate': {\n",
    "      'distribution': 'uniform',\n",
    "      'max': 0.1,\n",
    "      'min': 0\n",
    "    },\n",
    "    'optimizer': {\n",
    "      'values': ['adam', 'sgd']\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHesSoz85qMF"
   },
   "source": [
    "## Initialize the setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1PbIZ_xm5qMG",
    "ExecuteTime": {
     "end_time": "2023-11-24T15:15:43.506547500Z",
     "start_time": "2023-11-24T15:15:41.401435800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: il7wz2s8\n",
      "Sweep URL: https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"pp-sg-lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQH5jXxb5qMG"
   },
   "source": [
    "## Run the sweep agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkRbcMX35qMG"
   },
   "source": [
    "### Define Your Training Procedure\n",
    "\n",
    "Before we can actually execute the sweep, we need to define the training procedure that uses those values.\n",
    "\n",
    "In the functions below, we define a simple fully-connected neural network in PyTorch, and add the following `wandb` tools to log model metrics, visualize performance and output and track our experiments:\n",
    "* [**`wandb.init()`**](https://docs.wandb.com/library/init) ‚Äì Initialize a new W&B Run. Each Run is a single execution of the training function.\n",
    "* [**`wandb.config`**](https://docs.wandb.com/library/config) ‚Äì Save all your hyperparameters in a configuration object so they can be logged. Read more about how to use `wandb.config` [here](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-config/Configs_in_W%26B.ipynb).\n",
    "* [**`wandb.log()`**](https://docs.wandb.com/library/log) ‚Äì log model behavior to W&B. Here, we just log the performance; see [this Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Log_(Almost)_Anything_with_W%26B_Media.ipynb) for all the other rich media that can be logged with `wandb.log`.\n",
    "\n",
    "For more details on instrumenting W&B with PyTorch, see [this Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UMlizVTr5qMG",
    "ExecuteTime": {
     "end_time": "2023-11-24T15:15:43.506547500Z",
     "start_time": "2023-11-24T15:15:43.496539900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "\n",
    "        loader = build_dataset(config.batch_size)\n",
    "        network = build_network(config.fc_layer_size, config.dropout, config.num_layers)\n",
    "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            avg_loss = train_epoch(network, loader, optimizer)\n",
    "            wandb.log({\"loss\": avg_loss, \"epoch\": epoch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq8SQD9s5qMG"
   },
   "source": [
    "This cell defines the four pieces of our training procedure:\n",
    "`build_dataset`, `build_network`, `build_optimizer`, and `train_epoch`.\n",
    "\n",
    "All of these are a standard part of a basic PyTorch pipeline,\n",
    "and their implementation is unaffected by the use of W&B,\n",
    "so we won't comment on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PMNNnYkr5qMG",
    "ExecuteTime": {
     "end_time": "2023-11-24T15:15:43.934275800Z",
     "start_time": "2023-11-24T15:15:43.906140400Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO use this as sweep configuration\n",
    "parking_data_labels = [\"P24\", \"P44\", \"P42\", \"P33\", \"P23\", \"P25\", \"P21\", \"P31\", \"P54\", \"P53\", \"P32\", \"P22\", \"P52\", \"P51\", \"P43\", \"P41\"]\n",
    "parking_data_features = [\"ferien\", \"feiertag\", \"covid_19\", \"olma_offa\", \"temperature_2m_max\", \"temperature_2m_min\", \"rain_sum\", \"snowfall_sum\"]\n",
    "\n",
    "parking_data_all = [\"P24\", \"P44\", \"P42\", \"P33\", \"P23\", \"P25\", \"P21\", \"P31\", \"P54\", \"P53\", \"P32\", \"P22\", \"P52\", \"P51\", \"P43\", \"P41\", \"ferien\", \"feiertag\", \"covid_19\", \"olma_offa\", \"temperature_2m_max\", \"temperature_2m_min\", \"rain_sum\", \"snowfall_sum\"]\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_labels, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "def build_dataset(batch_size):\n",
    "    df = pd.read_csv(\"../data/preprocessing/pp_sg_cleaned.csv\", sep=\";\")\n",
    "\n",
    "    # TODO use more than one parking\n",
    "    df_shortened = df.head(10000)\n",
    "    single_label_df = df_shortened[[\"P24\"]]\n",
    "    single_label_tensor = torch.tensor(single_label_df.values, dtype=torch.float32)\n",
    "    \n",
    "    full_df = df_shortened[parking_data_all]\n",
    "    full_feature_tensor = torch.tensor(full_df.values, dtype=torch.float32)\n",
    "\n",
    "    # labels_df = df.head(1000)[parking_data_labels]\n",
    "    # features_df = df.head(1000)[parking_data_features]\n",
    "    # labels_tensor = torch.tensor(labels_df.values, dtype=torch.float32)\n",
    "    # features_tensor = torch.tensor(features_df.values, dtype=torch.float32)\n",
    "    # dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(full_feature_tensor, single_label_tensor)\n",
    "\n",
    "    # TODO Test / Train split\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def build_network(fc_layer_size, dropout, num_layers):\n",
    "    network = LSTMModel(input_size=len(parking_data_all), hidden_size=fc_layer_size, num_layers=num_layers, num_labels=1, dropout=dropout)\n",
    "\n",
    "    return network.to(device)\n",
    "\n",
    "\n",
    "def build_optimizer(network, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def train_epoch(network, loader, optimizer):\n",
    "    cumu_loss = 0\n",
    "    for _, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ‚û° Forward pass\n",
    "        loss = F.mse_loss(network(data), target)\n",
    "        cumu_loss += loss.item()\n",
    "\n",
    "        # ‚¨Ö Backward pass + weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        wandb.log({\"batch loss\": loss.item()})\n",
    "\n",
    "    return cumu_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIEd9-Gm5qMH"
   },
   "source": [
    "The cell below will launch an `agent` that runs `train` 5 times,\n",
    "usingly the randomly-generated hyperparameter values returned by the Sweep Controller. Execution takes under 5 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we're ready to start sweeping! üßπüßπüßπ\n",
    "\n",
    "Sweep Controllers, like the one we made by running `wandb.sweep`, sit waiting for someone to ask them for a `config` to try out.\n",
    "\n",
    "That someone is an `agent`, and they are created with `wandb.agent`.\n",
    "To get going, the agent just needs to know\n",
    "1. which Sweep it's a part of (`sweep_id`)\n",
    "2. which function it's supposed to run (here, `train`)\n",
    "3. (optionally) how many configs to ask the Controller for (`count`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KjgClaFq5qMH",
    "ExecuteTime": {
     "end_time": "2023-11-24T15:16:43.498619600Z",
     "start_time": "2023-11-24T15:15:46.387642300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: 7m5aa0sr with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 256\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.4\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tfc_layer_size: 50\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.03526977255632818\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jan/Projects/parcaster/model/wandb/run-20231124_161548-7m5aa0sr</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/7m5aa0sr' target=\"_blank\">dry-sweep-1</a></strong> to <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/7m5aa0sr' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/7m5aa0sr</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0474d77f24c148409382cf9ad86e49d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>‚ñà‚ñá‚ñÅ‚ñÜ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ</td></tr><tr><td>epoch</td><td>‚ñÅ</td></tr><tr><td>loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>10670.22656</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>12019.19307</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">dry-sweep-1</strong> at: <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/7m5aa0sr' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/7m5aa0sr</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231124_161548-7m5aa0sr/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Sweep Agent: Waiting for job.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Job received.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: 1tfefif0 with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 144\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.4\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tfc_layer_size: 50\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.03985025470122011\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jan/Projects/parcaster/model/wandb/run-20231124_161604-1tfefif0</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/1tfefif0' target=\"_blank\">playful-sweep-2</a></strong> to <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/1tfefif0' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/1tfefif0</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9a4aa2d001244ca93914ebf94787294"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ</td></tr><tr><td>loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>18865.76758</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>27254.05405</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">playful-sweep-2</strong> at: <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/1tfefif0' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/1tfefif0</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231124_161604-1tfefif0/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Sweep Agent: Waiting for job.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Job received.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: mq14vozd with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 48\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tfc_layer_size: 100\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.024182330951665654\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jan/Projects/parcaster/model/wandb/run-20231124_161620-mq14vozd</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/mq14vozd' target=\"_blank\">bright-sweep-3</a></strong> to <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/mq14vozd' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/mq14vozd</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.005 MB of 0.006 MB uploaded\\r'), FloatProgress(value=0.8561316872427983, max=1.0‚Ä¶",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "861b63845df64d3aae2e65a6739ea122"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÖ‚ñà</td></tr><tr><td>loss</td><td>‚ñà‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>6346.16797</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>7042.88201</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">bright-sweep-3</strong> at: <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/mq14vozd' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/mq14vozd</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231124_161620-mq14vozd/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: jahy1l8u with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 88\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.4\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tfc_layer_size: 100\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.038614419161151485\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jan/Projects/parcaster/model/wandb/run-20231124_161630-jahy1l8u</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/jahy1l8u' target=\"_blank\">dark-sweep-4</a></strong> to <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/jahy1l8u' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/jahy1l8u</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/.virtualenvs/parcaster/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0f80db7ed194620a4a1d6d1ad9d4295"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ</td></tr><tr><td>loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>6983.54199</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>15333.16838</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">dark-sweep-4</strong> at: <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/jahy1l8u' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/jahy1l8u</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231124_161630-jahy1l8u/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: nzsclyro with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 112\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.4\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tfc_layer_size: 200\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.08703586024199138\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jan/Projects/parcaster/model/wandb/run-20231124_161641-nzsclyro</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/nzsclyro' target=\"_blank\">treasured-sweep-5</a></strong> to <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/il7wz2s8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/nzsclyro' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/nzsclyro</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
