{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Bp7xn6t5qL_"
   },
   "source": [
    "\n",
    "# Hyperparameter Sweeps\n",
    "\n",
    "In this project, we use Hyperparemter sweeps with Pytorch on \"Weights & Biases\". For further details, check out this [Colab](http://wandb.me/sweeps-colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjckmLcx5qL_"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Start out by installing the experiment tracking library and setting up your free W&B account:\n",
    "\n",
    "1. Install with `!pip install`\n",
    "2. `import` the library into Python\n",
    "3. `.login()` so you can log metrics to your projects\n",
    "\n",
    "If you've never used Weights & Biases before,\n",
    "the call to `login` will give you a link to sign up for an account.\n",
    "W&B is free to use for personal and academic projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb -Uq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T18:00:09.219726500Z",
     "start_time": "2023-11-24T18:00:07.291315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import wandb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T18:00:09.220728800Z",
     "start_time": "2023-11-24T18:00:07.532630400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmr-perseus\u001B[0m (\u001B[33mparcaster\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T18:00:09.584283500Z",
     "start_time": "2023-11-24T18:00:08.132785700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiEyBrQm5qMB"
   },
   "source": [
    "## Defining the sweep config\n",
    "\n",
    "We define the sweep config via dict in our Jupyter notebook. You can find more information on sweeps in the [documentation](https://docs.wandb.com/sweeps/configuration).\n",
    "\n",
    "You can find a list of all configuration options [here](https://docs.wandb.com/library/sweeps/configuration) and a big collection of examples in YAML format [here](https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ilZtMXIA5qMC",
    "ExecuteTime": {
     "end_time": "2023-11-24T18:00:09.584283500Z",
     "start_time": "2023-11-24T18:00:09.568100300Z"
    }
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  'method': 'random',\n",
    "  'metric': {\n",
    "    'goal': 'minimize',\n",
    "    'name': 'loss'\n",
    "  },\n",
    "  'parameters': {\n",
    "    'batch_size': {\n",
    "      'distribution': 'q_log_uniform_values',\n",
    "      'max': 256,\n",
    "      'min': 32,\n",
    "      'q': 8\n",
    "    },\n",
    "    'dropout': {\n",
    "      'values': [0.3, 0.4, 0.5]\n",
    "    },\n",
    "    'num_layers': {\n",
    "      'values': [1, 2, 3]  \n",
    "    },\n",
    "    'epochs': {\n",
    "      'values': [1, 2, 3]\n",
    "    },\n",
    "    'fc_layer_size': {\n",
    "      'values': [50, 100, 200]\n",
    "    },\n",
    "    'learning_rate': {\n",
    "      'distribution': 'uniform',\n",
    "      'max': 0.1,\n",
    "      'min': 0\n",
    "    },\n",
    "    'optimizer': {\n",
    "      'values': ['adam', 'sgd']\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHesSoz85qMF"
   },
   "source": [
    "## Initialize the setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1PbIZ_xm5qMG",
    "ExecuteTime": {
     "end_time": "2023-11-24T18:00:11.697510300Z",
     "start_time": "2023-11-24T18:00:09.571760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 64y4a2f6\n",
      "Sweep URL: https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"pp-sg-lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQH5jXxb5qMG"
   },
   "source": [
    "## Run the sweep agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkRbcMX35qMG"
   },
   "source": [
    "### Define Your Training Procedure\n",
    "\n",
    "Before we can actually execute the sweep, we need to define the training procedure that uses those values.\n",
    "\n",
    "In the functions below, we define a simple fully-connected neural network in PyTorch, and add the following `wandb` tools to log model metrics, visualize performance and output and track our experiments:\n",
    "* [**`wandb.init()`**](https://docs.wandb.com/library/init) – Initialize a new W&B Run. Each Run is a single execution of the training function.\n",
    "* [**`wandb.config`**](https://docs.wandb.com/library/config) – Save all your hyperparameters in a configuration object so they can be logged. Read more about how to use `wandb.config` [here](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-config/Configs_in_W%26B.ipynb).\n",
    "* [**`wandb.log()`**](https://docs.wandb.com/library/log) – log model behavior to W&B. Here, we just log the performance; see [this Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Log_(Almost)_Anything_with_W%26B_Media.ipynb) for all the other rich media that can be logged with `wandb.log`.\n",
    "\n",
    "For more details on instrumenting W&B with PyTorch, see [this Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UMlizVTr5qMG",
    "ExecuteTime": {
     "end_time": "2023-11-24T18:06:55.032646300Z",
     "start_time": "2023-11-24T18:06:54.971903900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from models import LSTMModel, RNNModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "\n",
    "        loader = build_dataset(config.batch_size)\n",
    "        network = build_network(config.fc_layer_size, config.dropout, config.num_layers)\n",
    "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            avg_loss = train_epoch(network, loader, optimizer, config.batch_size)\n",
    "            wandb.log({\"loss\": avg_loss, \"epoch\": epoch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq8SQD9s5qMG"
   },
   "source": [
    "This cell defines the four pieces of our training procedure:\n",
    "`build_dataset`, `build_network`, `build_optimizer`, and `train_epoch`.\n",
    "\n",
    "All of these are a standard part of a basic PyTorch pipeline,\n",
    "and their implementation is unaffected by the use of W&B,\n",
    "so we won't comment on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "PMNNnYkr5qMG",
    "ExecuteTime": {
     "end_time": "2023-11-24T18:08:25.453885900Z",
     "start_time": "2023-11-24T18:08:25.440887400Z"
    }
   },
   "outputs": [],
   "source": [
    "# # TODO use this as sweep configuration\n",
    "# parking_data_labels = [\"P24\", \"P44\", \"P42\", \"P33\", \"P23\", \"P25\", \"P21\", \"P31\", \"P54\", \"P53\", \"P32\", \"P22\", \"P52\", \"P51\", \"P43\", \"P41\"]\n",
    "# parking_data_features = [\"ferien\", \"feiertag\", \"covid_19\", \"olma_offa\", \"temperature_2m_max\", \"temperature_2m_min\", \"rain_sum\", \"snowfall_sum\"]\n",
    "# \n",
    "# parking_data_all = [\"P24\", \"P44\", \"P42\", \"P33\", \"P23\", \"P25\", \"P21\", \"P31\", \"P54\", \"P53\", \"P32\", \"P22\", \"P52\", \"P51\", \"P43\", \"P41\", \"ferien\", \"feiertag\", \"covid_19\", \"olma_offa\", \"temperature_2m_max\", \"temperature_2m_min\", \"rain_sum\", \"snowfall_sum\"]\n",
    "\n",
    "def build_dataset(batch_size):\n",
    "    df = pd.read_csv(\"../data/preprocessing/pp_sg_cleaned.csv\", sep=\";\")\n",
    "\n",
    "    # TODO use more than one parking\n",
    "    df_shortened = df.head(10000)\n",
    "    target_col = \"P24\"\n",
    "    y = df_shortened[[target_col]]\n",
    "    X = df_shortened.drop(columns=[target_col, \"datetime\"])\n",
    "    \n",
    "    print(\"input_dim\", len(X.columns))\n",
    "\n",
    "    train_features = torch.Tensor(X.values)\n",
    "    train_targets = torch.Tensor(y.values)\n",
    "\n",
    "    train_dataset = TensorDataset(train_features, train_targets)\n",
    "\n",
    "    # TODO Test / Train split\n",
    "    return torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "def build_network(fc_layer_size, dropout, num_layers):\n",
    "    # TODO get input dim from df\n",
    "    network = LSTMModel(input_dim=23, hidden_dim=fc_layer_size, layer_dim=num_layers, output_dim=1, dropout_prob=dropout)\n",
    "\n",
    "    return network.to(device)\n",
    "\n",
    "\n",
    "def build_optimizer(network, optimizer, learning_rate):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=0.9)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def train_epoch(network, loader, optimizer, batch_size):\n",
    "    cumu_loss = 0\n",
    "    for _, (data, target) in enumerate(loader):\n",
    "        # data, target = data.to(device), target.to(device)\n",
    "        n_features = 23\n",
    "        \n",
    "        data = data.view([batch_size, -1, n_features]).to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # output = network(data.unsqueeze(0)).squeeze() # See https://medium.com/@mike.roweprediger/using-pytorch-to-train-an-lstm-forecasting-model-e5a04b6e0e67\n",
    "        \n",
    "        # ➡ Forward pass\n",
    "        loss = F.mse_loss(network(data), target)\n",
    "        cumu_loss += loss.item()\n",
    "\n",
    "        # ⬅ Backward pass + weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        wandb.log({\"batch loss\": loss.item()})\n",
    "\n",
    "    return cumu_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIEd9-Gm5qMH"
   },
   "source": [
    "The cell below will launch an `agent` that runs `train` 5 times,\n",
    "usingly the randomly-generated hyperparameter values returned by the Sweep Controller. Execution takes under 5 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we're ready to start sweeping! 🧹🧹🧹\n",
    "\n",
    "Sweep Controllers, like the one we made by running `wandb.sweep`, sit waiting for someone to ask them for a `config` to try out.\n",
    "\n",
    "That someone is an `agent`, and they are created with `wandb.agent`.\n",
    "To get going, the agent just needs to know\n",
    "1. which Sweep it's a part of (`sweep_id`)\n",
    "2. which function it's supposed to run (here, `train`)\n",
    "3. (optionally) how many configs to ask the Controller for (`count`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KjgClaFq5qMH",
    "ExecuteTime": {
     "end_time": "2023-11-24T18:09:22.343533400Z",
     "start_time": "2023-11-24T18:08:26.692759300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: 0mkrl3ra with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 200\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.5\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tfc_layer_size: 200\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.03770036179807364\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jan/Projects/parcaster/model/wandb/run-20231124_190828-0mkrl3ra</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/0mkrl3ra' target=\"_blank\">usual-sweep-11</a></strong> to <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/0mkrl3ra' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/0mkrl3ra</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim 23\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11ea3bdb571342e1af976ad7382d3cad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▁▁▃▇▃█▃▁▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>145177.5</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1349869.97779</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">usual-sweep-11</strong> at: <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/0mkrl3ra' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/0mkrl3ra</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231124_190828-0mkrl3ra/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: fi8zaxf1 with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 192\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tfc_layer_size: 100\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.09077860927745891\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jan/Projects/parcaster/model/wandb/run-20231124_190839-fi8zaxf1</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/fi8zaxf1' target=\"_blank\">earnest-sweep-12</a></strong> to <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/fi8zaxf1' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/fi8zaxf1</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim 23\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b7fbfa8f6434fb892c86e275777b517"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▁▁▁▁▁▁▁▂▂▇█▁▅▃▂▂▃▃▁▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>31869180.0</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2337782709.69306</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">earnest-sweep-12</strong> at: <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/fi8zaxf1' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/fi8zaxf1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231124_190839-fi8zaxf1/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: 1idod5zw with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 72\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.5\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tfc_layer_size: 100\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.07218432223875951\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jan/Projects/parcaster/model/wandb/run-20231124_190852-1idod5zw</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/1idod5zw' target=\"_blank\">serene-sweep-13</a></strong> to <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/1idod5zw' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/1idod5zw</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan/.virtualenvs/parcaster/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "839a3d9374cc4be89c56c75cdc6d510d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▆██▃▅▃▂▄▃▃▃▄▄▂▁▂▃▂▃▁▂▂▂▃▂▄▁▁▃▂▃▄▃▃▃▁▂▂▁▂</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>8867.8418</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>12846.49089</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">serene-sweep-13</strong> at: <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/1idod5zw' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/1idod5zw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231124_190852-1idod5zw/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: yodfxbrd with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 112\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.4\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tfc_layer_size: 100\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.08074381287944647\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jan/Projects/parcaster/model/wandb/run-20231124_190905-yodfxbrd</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/yodfxbrd' target=\"_blank\">polar-sweep-14</a></strong> to <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/yodfxbrd' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/yodfxbrd</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim 23\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d26110ba481f42a59eb46118ea27f284"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▂▅▃▃▂▂▂▂▂▁▁▂▃▁▁▂▁▂▁▃▂▂▂▁▁▂▂▁▂▁▂▁▂▂▂▂▁▁▁</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>11448.63965</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>7185.22599</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">polar-sweep-14</strong> at: <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/yodfxbrd' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/yodfxbrd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231124_190905-yodfxbrd/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: ygvru937 with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 128\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.3\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tfc_layer_size: 100\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.0461318299138474\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/jan/Projects/parcaster/model/wandb/run-20231124_190916-ygvru937</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/ygvru937' target=\"_blank\">swift-sweep-15</a></strong> to <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/parcaster/pp-sg-lstm' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/sweeps/64y4a2f6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/ygvru937' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/ygvru937</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim 23\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2c8edc5dcfd4036b83c381a11e36f8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▅▆█▄▅▃▂▅▄▃▂▄▄▃▂▂▂▃▂▂▂▁▂▂▁▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>8671.67773</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>15713.80638</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">swift-sweep-15</strong> at: <a href='https://wandb.ai/parcaster/pp-sg-lstm/runs/ygvru937' target=\"_blank\">https://wandb.ai/parcaster/pp-sg-lstm/runs/ygvru937</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231124_190916-ygvru937/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
